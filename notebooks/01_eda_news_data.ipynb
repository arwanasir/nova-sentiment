{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27799c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ee1b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "229d082a",
   "metadata": {},
   "source": [
    "#loading the data and basic infos about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5624ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw_analyst_ratings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f77aa5f",
   "metadata": {},
   "source": [
    "#shapes of the data, overvies , missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0140971",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84115fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d736fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" DATASET OVERVIEW\")\n",
    "print(f\"Total records: {df.shape[0]:,}\")\n",
    "print(f\"Total columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"COLUMN NAMES\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DATA TYPES & MISSING VALUES\")\n",
    "info_df = pd.DataFrame({\n",
    "    'Data Type': df.dtypes,\n",
    "    'Missing Values': df.isnull().sum(),\n",
    "    'Missing %': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "    'Unique Values': df.nunique()\n",
    "})\n",
    "display(info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b59397",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BASIC STATISTICS\")\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "print(\"SAMPLE HEADLINES\")\n",
    "for i, headline in enumerate(df['headline'].head(5)):\n",
    "    print(f\"{i+1}. {headline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DATA QUALITY CHECKS\")\n",
    "\n",
    "\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicates}\")\n",
    "\n",
    "\n",
    "empty_headlines = df['headline'].isna().sum()\n",
    "print(f\"Empty headlines: {empty_headlines}\")\n",
    "\n",
    "\n",
    "if 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    invalid_dates = df['date'].isna().sum()\n",
    "    print(f\"Invalid dates: {invalid_dates}\")\n",
    "    \n",
    "    if invalid_dates == 0:\n",
    "        date_range = df['date'].agg(['min', 'max'])\n",
    "        print(f\"Date range: {date_range['min']} to {date_range['max']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840203bd",
   "metadata": {},
   "source": [
    "Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62537ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#headline length \n",
    "df['headline_length'] = df['headline'].str.len()\n",
    "df['word_count'] = df['headline'].str.split().str.len()\n",
    "\n",
    "print(\"Headline Length Statistics:\")\n",
    "print(df['headline_length'].describe())\n",
    "\n",
    "print(\"Word Count Statistics:\")\n",
    "print(df['word_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2762c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#publisher analysis\n",
    "#counting articles per publisher\n",
    "publisher_counts = df['publisher'].value_counts()\n",
    "print(f\"total unique publisher: {len(publisher_counts)}\")\n",
    "\n",
    "print(\"\\nTop 15 Publishers by Article Count:\")\n",
    "top_publishers = publisher_counts.head(15)\n",
    "for i, (publisher, count) in enumerate(top_publishers.items(), 1):\n",
    "    print(f\"{i:2d}. {publisher}: {count:>4} articles\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#publication date trend analysis\n",
    "df['datetime'] = pd.to_datetime(df['date'])\n",
    "df['date_only'] = df['datetime'].dt.date\n",
    "df['day_of_week'] = df['datetime'].dt.day_name()\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['week'] = df['datetime'].dt.isocalendar().week\n",
    "\n",
    "print(\"Date Range Analysis:\")\n",
    "print(f\"Earliest publication: {df['datetime'].min()}\")\n",
    "print(f\"Latest publication: {df['datetime'].max()}\")\n",
    "print(f\"Total time span: {df['datetime'].max() - df['datetime'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ce27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count articles per day\n",
    "daily_counts = df['date_only'].value_counts().sort_index()\n",
    "print(f\"Total days with publications: {len(daily_counts)}\")\n",
    "print(f\"Average articles per day: {daily_counts.mean():.1f}\")\n",
    "print(f\"Busiest day: {daily_counts.idxmax()} with {daily_counts.max()} articles\")\n",
    "print(f\"Quietest day: {daily_counts.idxmin()} with {daily_counts.min()} articles\")\n",
    "\n",
    "\n",
    "mean_daily = daily_counts.mean()\n",
    "std_daily = daily_counts.std()\n",
    "spike_threshold = mean_daily + std_daily\n",
    "spike_days = daily_counts[daily_counts > spike_threshold]\n",
    "\n",
    "print(f\"\\n Publication Spikes (>{spike_threshold:.1f} articles):\")\n",
    "print(f\"Found {len(spike_days)} days with unusually high publication volume\")\n",
    "for date, count in spike_days.head(10).items():\n",
    "    print(f\"  {date}: {count} articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574ce027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Counter\n",
    "\n",
    "\n",
    "print(\"EVENT-DRIVEN PUBLICATION ANALYSIS\")\n",
    "\n",
    "\n",
    "print(\"Investigating spike days for potential market events...\")\n",
    "\n",
    "for date, count in spike_days.head(5).items():\n",
    "    day_articles = df[df['date_only'] == date]\n",
    "    print(f\"\\n {date} - {count} articles (Spike Day):\")\n",
    "    \n",
    "   \n",
    "    day_headlines = ' '.join(day_articles['headline'].astype(str))\n",
    "    words = day_headlines.lower().split()\n",
    "    common_words = Counter(words).most_common(8)\n",
    "    \n",
    "    print(f\"   Top keywords: {[word for word, freq in common_words if len(word) > 3]}\")\n",
    "    print(f\"   Sample headlines:\")\n",
    "    for headline in day_articles['headline'].head(2):\n",
    "        print(f\"     - {headline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8113f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
